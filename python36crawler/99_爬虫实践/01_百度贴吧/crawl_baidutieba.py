#!/usr/bin/env python
# encoding: utf-8

"""
@python_version: python3.6
@file: crawl_baidutieba.py
@time: 2017/8/18 10:03
"""

import os
import sys
import requests
from bs4 import BeautifulSoup


def get_html(url):
    """
    æŸ¥è¯¢ç½‘é¡µï¼Œè¿”å› html ç½‘é¡µç»“æœ
    :param url:
    :return:
    """
    try:
        r = requests.get(url, timeout=30)  # 30 ç§’è¶…æ—¶
        r.raise_for_status()

        r.encoding = 'utf-8'
        # è¿™é‡Œæˆ‘ä»¬çŸ¥é“ç™¾åº¦è´´å§çš„ç¼–ç æ˜¯utf-8ï¼Œæ‰€ä»¥æ‰‹åŠ¨è®¾ç½®çš„ã€‚çˆ¬å»å…¶ä»–çš„é¡µé¢æ—¶å»ºè®®ä½¿ç”¨ï¼š
        # r.endcodding = r.apparent_endconding

        return r.text

    except:
        return "ERROR"


def get_content(url):
    """
    åˆ†æè´´å§çš„ç½‘é¡µæ–‡ä»¶ï¼Œæ•´ç†ä¿¡æ¯ï¼Œä¿å­˜åœ¨åˆ—è¡¨å˜é‡ä¸­
    :param url:  baidutiba_url
    :return:  dict
    """

    """ æ ‡é¢˜ä¸åœ°å€
    <a href="/p/5264880782" title="ç¬¬ä¸€å­£ç¬¬åé›†" target="_blank" class="j_th_tit ">ç¬¬ä¸€å­£ç¬¬åé›†</a>
    """

    """ä¸»é¢˜ä½œè€…
    <span class="tb_icon_author " title="ä¸»é¢˜ä½œè€…: ğŸ¨çŒªçŒªçš„ä½ " data-field="{&quot;user_id&quot;:308280638}">
        <i class="icon_author"></i>
        <span class="frs-author-name-wrap">
            <a data-field="{&quot;un&quot;:&quot;237102576&quot;}"
                class="frs-author-name j_user_card "
                href="/home/main/?un=237102576&amp;ie=utf-8&amp;fr=frs"
                target="_blank">
                <img src="//tb1.bdstatic.com/tb/cms/nickemoji/2-5.png"
                class="nicknameEmoji" style="width:13px;height:13px">çŒªçŒªçš„ä½ 
            </a>
        </span>
    </span>
    """

    """åˆ›å»ºæ—¶é—´
    <span class="pull-right is_show_create_time" title="åˆ›å»ºæ—¶é—´">8-14</span>
    """

    """å›å¤æ•°é‡
    """

    contents = []

    # è·å–ç½‘é¡µå†…å®¹
    html = get_html(url)

    # open('tbbt.html', 'w', encoding='utf-8').write(html)
    # html = open('tbbt.html', 'r', encoding='utf-8').read()
    # è§£æç½‘é¡µ
    soup = BeautifulSoup(html, 'lxml')

    # æ‰¾åˆ°æœ€ä¸Šå±‚ä¸€ä¸ªçš„ li tagï¼ŒåŒ…å«æ¯ä¸ªå¸–å­çš„ä¿¡æ¯
    liTags = soup.find_all('li', attrs={'class': ' j_thread_list clearfix'})

    # print(type(liTags))

    # åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨å¸–å­ä¿¡æ¯
    comment = {}
    for li in liTags:

        try:
            # comment['title'] = li.find('a', attrs={'class': 'j_th_tit '}).test.strip()
            # comment['title'] = li.find('a', attrs={'class': 'j_th_tit '}).text.strip()
            # comment['title'] = li.find('a', attrs={'class': 'j_th_tit '}).text.strip()
            # print(li.find('a', attrs={'class': 'j_th_tit '}).text.strip())
            # print(li.find('a', attrs={'class': 'j_th_tit '}))
            # print(comment['title'])

            """é‡‡é›†æ–‡ç« æ ‡é¢˜ä¸"""
            title_tag = li.find('a', attrs={'class': 'j_th_tit '})
            # print(title_tag)
            # print(title_tag.text.strip())
            # print(title_tag.text)  # å– <a> æ ‡ç­¾çš„æ–‡æœ¬ä¿¡æ¯ï¼Œå†…å®¹ä¸ title åŒã€‚
            # print(title_tag['title'])
            # print('{}{}'.format('http://tieba.baidu.com', title_tag['href']))
            tie_title = title_tag['title'].strip()
            comment[tie_title] = {}

            comment[tie_title]['title'] = title_tag.text.strip()
            comment[tie_title]['link'] = '{}{}'.format('http://tieba.baidu.com', title_tag['href'])

            """é‡‡é›†ä½œè€…åå­—"""
            """
            <a data-field="{&quot;un&quot;:&quot;237102576&quot;}"
                class="frs-author-name j_user_card "
                href="/home/main/?un=237102576&amp;ie=utf-8&amp;fr=frs"
                target="_blank">
                <img src="//tb1.bdstatic.com/tb/cms/nickemoji/2-5.png"
                class="nicknameEmoji" style="width:13px;height:13px">çŒªçŒªçš„ä½ 
            </a>
            """
            # author_tag = soup.find('span', attrs={'class': 'tb_icon_author '})
            # comment[tie_title]['author'] = author_tag['title'].strip()
            author_tag = soup.find('a', attrs={'class': 'frs-author-name j_user_card '})
            comment[tie_title]['author'] = author_tag.text.strip()

            """é‡‡é›†æ–‡ç« åˆ›å»ºæ—¶é—´"""
            create_time_tag = soup.find('span', attrs={'class': 'pull-right is_show_create_time'})
            comment[tie_title]['create_time'] = create_time_tag.text.strip()

            """é‡‡é›†å¸–å­å›å¤æ•°é‡"""
            """å›å¤æ•°é‡
            <span class="threadlist_rep_num center_text" title="å›å¤">1</span>
            """
            reply_tag = soup.find('span', attrs={'class': "threadlist_rep_num center_text"})
            # repy_num = reply_tag.text.strip()
            comment[tie_title]['reply_num'] = reply_tag.text.strip()

            # print('{}\t{}\t{}\t{}\t{}'.format(comment[tie_title]['title']))

            # print("=========")
            result = ''
            for k in comment[tie_title]:
                # print(k)
                result += "{}\t".format(comment[tie_title][k])

            print(result)

        except Exception as e:
            print(e)

            # print(comment)
            # sys.exit(0)
            # sys.exit(0)
            # return comment


def threading_mode(url):
    import threading
    import time
    from random import randint, random
    deep = 10

    for dp in range(0, deep):
        url_tmp = "{}&pn={}".format(url, dp * 50)
        print(url_tmp)
        # time.sleep(randint(1, 3))
        time.sleep(random())

        t = threading.Thread(target=get_content, args=(url_tmp,))
        t.start()


if __name__ == "__main__":
    url = "http://tieba.baidu.com/f?kw=%E7%94%9F%E6%B4%BB%E5%A4%A7%E7%88%86%E7%82%B8&ie=utf-8"
    # get_content(url)
    threading_mode(url)
